**### Make a fork or copy of this repo and fill in your team submission details! ###**

# AMD_Robotics_Hackathon_2025_Almassas_Assistant
*Submission is for the task you did in Mission 2, since Mission 1 was a "hello world" task for every team.*

## Team Information

**Team:** * team number 5, Footakagool, Karim Ziadi

**Summary:** *ðŸš€ A brief description of your work ðŸš€*

This project, presents a mobile manipulation system designed to operate within common human environments, such as a tabletop or konbini counter. Our robot hardware leverages the robustness of open-source designs, specifically integrating components from the Lekiwi and XLerobot projects.

We trained the mobile arm for two distinct, challenging manipulation tasks, demonstrating both precise object relocation and high-dexterity grip control:

*** Object Relocation (Pick-and-Place): *** The robot executes a multi-step pick-and-place sequence. It picks up a bottle and then navigates to and places it inside a designated blue container. This task validates the robot's ability to perform reliable, multi-stage industrial-style object handling.

[Video Demonstration: Pick and Place Task Using Replay Function](https://youtu.be/CfoK_wLZdRo)

---

*** High-Dexterity Precision Grip: *** This model showcases advanced manipulation capability. Using a suction cup gripper, the robot is tasked with isolating and picking a single business card from a densely stacked box. This task is nearly impossible to perform reliably with conventional parallel grippers and demonstrates the effectiveness of our dexterity-focused training for handling thin, tightly packed objects.



## Judging Criteria

### 1. Mission 2 Description (10 points)
- *Real world application of your mission*


### 2. Creativity (30 points)
- *What is novel or unique in your approach?*
- *Innovation in design, methodology, or application*

### 3. Technical implementations (20 points)
- *Teleoperation / Dataset capture*
    - *<Image/video of teleoperation or dataset capture>*
- *Training*
- *Inference*
    - *<Image/video of inference eval>*

### 4. Ease of use (10 points)
- *How generalizable is your implementation across tasks or environments?*
- *Flexibility and adaptability of the solution*
- *Types of commands or interfaces needed to control the robot*


## Code submission

This is the directory tree of this repo, you need to fill in the `mission` directory with your submission details.

```terminal
AMD_Robotics_Hackathon_2025_ProjectTemplate-main/
â”œâ”€â”€ README.md
â””â”€â”€ mission
    â”œâ”€â”€ code
    â”‚Â Â  â””â”€â”€ <code and script>
    â””â”€â”€ wandb
        â””â”€â”€ <latest run directory copied from wandb of your training job>
```


The `latest-run` is generated by wandb for your training job. Please copy it into the wandb sub directory of you Hackathon Repo.

The whole dir of `latest-run` will look like below:

```terminal
$ tree outputs/train/smolvla_so101_2cube_30k_steps/wandb/
outputs/train/smolvla_so101_2cube_30k_steps/wandb/
â”œâ”€â”€ debug-internal.log -> run-20251029_063411-tz1cpo59/logs/debug-internal.log
â”œâ”€â”€ debug.log -> run-20251029_063411-tz1cpo59/logs/debug.log
â”œâ”€â”€ latest-run -> run-20251029_063411-tz1cpo59
â””â”€â”€ run-20251029_063411-tz1cpo59
    â”œâ”€â”€ files
    â”‚Â Â  â”œâ”€â”€ config.yaml
    â”‚Â Â  â”œâ”€â”€ output.log
    â”‚Â Â  â”œâ”€â”€ requirements.txt
    â”‚Â Â  â”œâ”€â”€ wandb-metadata.json
    â”‚Â Â  â””â”€â”€ wandb-summary.json
    â”œâ”€â”€ logs
    â”‚Â Â  â”œâ”€â”€ debug-core.log -> /dataset/.cache/wandb/logs/core-debug-20251029_063411.log
    â”‚Â Â  â”œâ”€â”€ debug-internal.log
    â”‚Â Â  â””â”€â”€ debug.log
    â”œâ”€â”€ run-tz1cpo59.wandb
    â””â”€â”€ tmp
        â””â”€â”€ code
```

**NOTES**

1. The `latest-run` is the soft link, please make sure to copy the real target directory it linked with all sub dirs and files.
2. Only provide (upload) the wandb of your last success pre-trained model for the Mission.


## Additional Links
*For example, you can provide links to:*

- *Link to a video of your robot performing the task*
- *URL of your dataset in Hugging Face*
- *URL of your model in Hugging Face*
- *Link to a blog post describing your work*